{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "mode.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmohammad78/deep-learning-projects/blob/feature%2Fvariational-autoencoder-mnist/variational-autoencoder/mode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1iPfzWR-FmV"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB7u4S8Y-OQS"
      },
      "source": [
        "def encoder_layers(inputs,latent_dim):\n",
        "  x = tf.keras.layers.Conv2D(filters=32,padding=\"same\",name=\"encoder_conv1\" , activation=\"relu\" , kernel_size=3 , strides=2)(inputs)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2D(filters=64,padding=\"same\",name=\"encoder_conv2\" , activation=\"relu\" , kernel_size=3 , strides=2)(x)\n",
        "  batch_2 = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Flatten(name=\"encoder_flatten\")(batch_2)\n",
        "  x = tf.keras.layers.Dense(20,activation=\"relu\",name=\"encode_dense\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  \n",
        "  mu = tf.keras.layers.Dense(latent_dim,name=\"latent_mu\")(x)\n",
        "  sigma = tf.keras.layers.Dense(latent_dim,name=\"latent_sigma\")(x)\n",
        "  return mu , sigma , batch_2.shape"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQakom8c-fXo"
      },
      "source": [
        "class Sampling(tf.keras.layers.Layer):\n",
        "  def call(self,inputs):\n",
        "    mu , sigma = inputs\n",
        "    batch = tf.shape(mu)[0]\n",
        "    dim = tf.shape(mu)[1]\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(batch,dim))\n",
        "    return mu + tf.exp(0.5 * sigma) * epsilon\n",
        "    "
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7UK5ry0-hTH"
      },
      "source": [
        "def encoder_model(LATENT_DIM,input_shape):\n",
        "  inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "  print(inputs.shape)\n",
        "  mu , sigma , conv_shape = encoder_layers(inputs , latent_dim=LATENT_DIM)\n",
        "  z = Sampling()((mu,sigma))\n",
        "  model = tf.keras.Model(inputs,outputs=[mu,sigma,z])\n",
        "  return model,conv_shape"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgffQB1Q2Qfc"
      },
      "source": [
        ""
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-pmDBHwFFDy"
      },
      "source": [
        "def decoder_layers(inputs,conv_shape):\n",
        "  units = conv_shape[1] * conv_shape[2] * conv_shape[3]\n",
        "  x = tf.keras.layers.Dense(units,activation=\"relu\",name=\"decoder_dens1\")(inputs)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  x = tf.keras.layers.Reshape((conv_shape[1],conv_shape[2],conv_shape[3]),name=\"decoder_shape\")(x)\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters=64,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\" , name=\"decoder_conv2d_2\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\" , name=\"decoder_conv2d3\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters=1,kernel_size=3,strides=1,padding=\"same\",activation=\"sigmoid\" , name=\"decoder_final\")(x)\n",
        "  return x"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EO_lv4MNDFq"
      },
      "source": [
        "def decoder_model(latent_dim,conv_shape):\n",
        "   inputs = tf.keras.layers.Input(shape=(latent_dim,))\n",
        "   outputs = decoder_layers(inputs,conv_shape)\n",
        "   model = tf.keras.Model(inputs,outputs)\n",
        "   return model"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IhLCBAb5fK3"
      },
      "source": [
        "def k1_reconstrcution_loss(output,mu , sigma):\n",
        "  kl_loss = 1 + sigma - tf.square(mu) - tf.math.exp(sigma)\n",
        "  return tf.reduce_mean(kl_loss) * -0.5\n"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9xQKJefbi6Y"
      },
      "source": [
        "def vae_model(encoder, decoder , input_shape):\n",
        "  inputs = tf.keras.layers.Input(shape=(input_shape))\n",
        "  mu = encoder(inputs)[0]\n",
        "  sigma = encoder(inputs)[1]\n",
        "  z = encoder(inputs)[2]\n",
        "  reconstructed = decoder(z)\n",
        "  model = tf.keras.Model(inputs=inputs,outputs = reconstructed)\n",
        "  loss = k1_reconstrcution_loss(z , mu , sigma)\n",
        "  model.add_loss(loss)\n",
        "  return model"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jcWs31EFSp4",
        "outputId": "14d3485b-bb28-4596-b1c7-548cd6d08130",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "latent_dim = 32\n",
        "x_train.shape"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-5fnTGrULID"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rRj4IkYc3Le",
        "outputId": "72b0e9a3-42a5-470f-c32a-8e24a06d88e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "source": [
        "\n",
        "encoder_out , conv_shape = encoder_model(LATENT_DIM = 32,input_shape = (28,28,1))\n",
        "decoder_out = decoder_model(32,conv_shape)\n",
        "vae = vae_model(encoder_out, decoder_out, (28,28,1))\n",
        "epochs = 2\n",
        "for epoch in range(epochs):\n",
        "  for step , x_batch_train in enumerate(train_dataset):\n",
        "    with tf.GradientTape() as tape:\n",
        "      reconstrcuted = vae(x_batch_train)\n",
        "      flattened_input  = tf.reshape(x_batch_train,shape=[-1])\n",
        "      flattened_output  = tf.reshape(reconstrcuted,shape=[-1])\n",
        "      loss = bce_loss(flattened_input,flattened_output) * 764\n",
        "      loss += sum(vae.losses)\n",
        "    grads = tape.gradient(loss,vae.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads,vae.trainable_weights))\n",
        "    loss_metric(loss)"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-246-d930ad09b385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mx_batch_train\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mreconstrcuted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mflattened_input\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mflattened_output\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstrcuted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         training=training_mode):\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    268\u001b[0m                              \u001b[0;34m' is incompatible with layer '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                              \u001b[0;34m': expected shape='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                              ', found shape=' + display_shape(x.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer model_148: expected shape=(None, 28, 28, 1), found shape=(64, 784)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7jR2LQ_D2MX"
      },
      "source": [
        ""
      ],
      "execution_count": 171,
      "outputs": []
    }
  ]
}