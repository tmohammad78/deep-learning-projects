{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "mode.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmohammad78/deep-learning-projects/blob/feature%2Fvariational-autoencoder-mnist/variational-autoencoder/mode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1iPfzWR-FmV"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB7u4S8Y-OQS"
      },
      "source": [
        "def encoder_layers(inputs,latent_dim):\n",
        "  x = tf.keras.layers.Conv2D(filters=32,padding=\"same\",name=\"encoder_conv1\" , activation=\"relu\" , kernel_size=3 , strides=2)(inputs)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2D(filters=64,padding=\"same\",name=\"encoder_conv2\" , activation=\"relu\" , kernel_size=3 , strides=2)(x)\n",
        "  batch_2 = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Flatten(name=\"encoder_flatten\")(batch_2)\n",
        "  x = tf.keras.layers.Dense(20,activation=\"relu\",name=\"encode_dense\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  mu = tf.keras.layers.Dense(latent_dim,name=\"latent_mu\")(x)\n",
        "  sigma = tf.keras.layers.Dense(latent_dim,name=\"latent_sigma\")(x)\n",
        "  return mu , sigma , batch_2.shape"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQakom8c-fXo"
      },
      "source": [
        "class Sampling(tf.keras.layers.Layer):\n",
        "  def call(self,inputs):\n",
        "    mu , sigma = inputs\n",
        "    batch = tf.shape(mu)[0]\n",
        "    dim = tf.shape(mu)[1]\n",
        "    eplison = tf.keras.backend.random_normal(shape=(batch,dim))\n",
        "    return mu + tf.exp(0.5 * sigma) * spsilon\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7UK5ry0-hTH"
      },
      "source": [
        "def encoder_model(LATENT_DIM,input_shape):\n",
        "  inputs = tf.keras.layers.Input(input=input_shape)\n",
        "  mu , sigma , conv_shape = encoder_layers(inputs , latent_dim=LATENT_DIM)\n",
        "  z = Sampling()((mu,sigma))\n",
        "  model = tf.keras.Model(inputs,outputs=[mu,sigma,z])\n",
        "  return model,conv_shape"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgffQB1Q2Qfc"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-pmDBHwFFDy"
      },
      "source": [
        "def decoder_layers(inputs,conv_shape):\n",
        "  units = conv_shape[1] * conv_shape[2] * conv_shape[3]\n",
        "  x = tf.keras.layer.Dense(units,activation=\"relu\",name=\"decoder_dens1\")(inputs)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  x = tf.keras.layers.Reshape((conv_shape[1],conv_shape[2],conv_shape[3]),name=\"decoder_shape\")(x)\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters=64,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\" , name=\"decoder_conv2d_2\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters=32,kernel_size=3,strides=2,padding=\"same\",activation=\"relu\" , name=\"decoder_conv2d3\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters=1,kernel_size=3,strides=1,padding=\"same\",activation=\"sigmoid\" , name=\"decoder_final\")(x)\n",
        "  return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EO_lv4MNDFq"
      },
      "source": [
        "def decoder_model(latent_dim,conv_shape):\n",
        "   inputs = tf.keras.layers.Input(shape=(latent_dim,))\n",
        "   outputs = decoder_layers(inputs,conv_shape)\n",
        "   model = tf.keras.Model(inputs,outputs)\n",
        "   return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IhLCBAb5fK3"
      },
      "source": [
        "def k1_reconstrcution_loss(input,output,mu , sigma):\n",
        "  kl_loss = 1 + sigma - tf.square(mu) - tf.math.exp(sigma)\n",
        "  return tf.reduce_mean(kl_loss) * -0.5\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9xQKJefbi6Y"
      },
      "source": [
        "def vae_model(encoder, decoder , input_shape):\n",
        "  inputs = tf.keras.layers.Inputs(shape=(input_shape))\n",
        "  mu = encoder(inputs)[0]\n",
        "  sigma = encoder(inputs)[1]\n",
        "  z = encoder(inputs)[2]\n",
        "  reconstructed = decoder(z)\n",
        "  model = tf.keras.Model(inputs=inputs,outputs = reconstructed)\n",
        "  loss = k1_reconstrcution_loss(inputs,z , mu , sigma)\n",
        "  model.add_loss(loss)\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rRj4IkYc3Le"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}